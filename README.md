# 基于山西日报的数据分析
`Python` `html`

本项目是简单的涉及到数据爬取、数据简单清洗、数据可视化的项目。

1.scrapy网络爬虫框架来爬取数据(见图中红色部分)，自行搜索scrapy框架如何使用(如果你想爬取新的数据);

2.数据存储到了数据存储文件夹(见图中橙色部分);

3.基于存储的csv文件和pyEcharts库根据词语频率、新闻长度、主题分布生成相关图(见图中黄色部分);

![image](https://github.com/user-attachments/assets/c5088498-b0e9-433f-b156-cf17bcc0bfd0)
